{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import json\n",
    "import sys\n",
    "# third party imports\n",
    "from geopy.distance import distance\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# local imports\n",
    "sys.path.append('..')\n",
    "from geo_llama.main import GeoLlama\n",
    "from geo_llama.model import TopoModel, RAGModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the GeoLlama model on the News2024 dataset\n",
    "this notbook goes through th eprocess of testing the GeoLlama model on the News2024 dataset. The model is very computational intensive, even with Unsloth and quantization. The model uses roughly 12Gb of GPU RAM. For efficiency, it is recommended to be run on the L4 GPU available on colab pro. \n",
    "## 1. Loading the dataset\n",
    "We'll load the dataset and remove the articles which have no toponyms. This same process has been done with other LLMs tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles : 50\n"
     ]
    }
   ],
   "source": [
    "with open('../data/test_data/News2024.json', 'r') as f:\n",
    "    true_data = json.load(f)\n",
    "    \n",
    "# remove any articles without topnoyms\n",
    "true_data = [d for d in true_data if len(d['toponyms'])>0]   \n",
    "print(f'Total number of articles : {len(true_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Geoparse using GeoLlama\n",
    "We'll now use the `geoparse` method in GeoLlama to parse each text. Note that we are not using the translation module in this instance as all texts are in english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "topo_model = TopoModel(model_name='JoeShingleton/GeoLlama_7b_toponym', \n",
    "                       prompt_path='data/prompt_templates/prompt_template.txt',\n",
    "                       instruct_path='data/prompt_templates/topo_instruction.txt',\n",
    "                       input_path=None,\n",
    "                       config_path='data/config_files/model_config.json')\n",
    "\n",
    "rag_model = RAGModel(model_name='JoeShingleton/GeoLlama_7b_RAG',\n",
    "                       prompt_path='data/prompt_templates/prompt_template.txt',\n",
    "                       instruct_path='data/prompt_templates/rag_instruction.txt',\n",
    "                       input_path='data/prompt_templates/rag_input.txt',\n",
    "                       config_path='data/config_files/model_config.json')\n",
    "\n",
    "geo_llama = GeoLlama(topo_model, rag_model)\n",
    "\n",
    "\n",
    "results = []\n",
    "for d in tqdm(true_data):\n",
    "  results.append(geo_llama.geoparse(d['text']))\n",
    "# save the results\n",
    "with open('geollama_news2024_results.json', 'w') as f:\n",
    "  json.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse the results\n",
    "We will consider the toponym extraction accuracy and the toponym resolution accuracy. For toponym extraction we are interested in the proportion of toponyms in the text the model identifies. Note that we are expecting the model to tell us where in the text the toponym occurs, so this may be a different metric to other reported metrics. For toponym resolution we are interested in the distance betweeen true-positive toponyms resolved by the model and the assigned location in the dataset. We use Geopy's standard geodesic distance method for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'../data/results/geollama_news2024_results.json', 'r') as f:\n",
    "    pred_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topo_precision = []\n",
    "topo_recall = []\n",
    "topo_f1 = []\n",
    "topo_distance = []\n",
    "\n",
    "def get_toponym_metrics(true_toponyms:list, pred_toponyms:list)->dict[str,int]:\n",
    "    true_positives = len([t for t in pred_toponyms if t in true_toponyms])\n",
    "    false_positives = len([t for t in pred_toponyms if t not in true_toponyms])\n",
    "    false_negatives = len([t for t in true_toponyms if t not in pred_toponyms])\n",
    "    return {'TP':true_positives, 'FP':false_positives, 'FN':false_negatives}\n",
    "\n",
    "def get_accuracy_metrics(topo_metrics: dict[str, int]) -> dict[str, float]:\n",
    "    tp = topo_metrics['TP']\n",
    "    fp = topo_metrics['FP']\n",
    "    fn = topo_metrics['FN']\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    return {'precision': precision, 'recall': recall, 'F1': f1}\n",
    "\n",
    "for true, pred in zip(true_data, pred_data):\n",
    "    # skip if no toponyms in text\n",
    "    if len(true['toponyms'])==0:\n",
    "        continue\n",
    "    # get toponyms\n",
    "    true_toponyms = [t['word'] for t in true['toponyms']]\n",
    "    pred_toponyms = [t['name'] for t in pred]\n",
    "    # get true/false positives/negatives\n",
    "    toponym_metrics = get_toponym_metrics(true_toponyms, pred_toponyms)\n",
    "    # get prec, rec, f1\n",
    "    accuracy_metrics = get_accuracy_metrics(toponym_metrics)\n",
    "    topo_precision.append(accuracy_metrics['precision'])\n",
    "    topo_recall.append(accuracy_metrics['recall'])\n",
    "    topo_f1.append(accuracy_metrics['F1'])\n",
    "    ### distances\n",
    "    for pred_topo in pred:\n",
    "        if pred_topo['name'] not in true_toponyms:\n",
    "            continue\n",
    "        pred_coords = (float(pred_topo['latitude']), float(pred_topo['longitude']))\n",
    "        true_location = [t for t in true['toponyms'] if t['word']==pred_topo['name']][0]\n",
    "        true_coords = (float(true_location['lat']), float(true_location['lon']))\n",
    "        topo_distance.append(distance(true_coords, pred_coords))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro precision: 0.761\n",
      "Macro recall: 0.716\n",
      "Macro F1: 0.719\n",
      "#####################\n",
      "Mean distance : 255.5\n",
      "Median distance : 0.011\n",
      "Acc@1km : 0.685\n",
      "Acc@10km : 0.802\n",
      "Acc@50km : 0.858\n",
      "Acc@80km : 0.873\n",
      "Acc@161km : 0.898\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "macro_precision = np.mean(topo_precision)\n",
    "macro_recall = np.mean(topo_recall)\n",
    "macro_f1 = np.mean(topo_f1)\n",
    "\n",
    "mean_d = np.mean([d.km for d in topo_distance])\n",
    "median_d = np.median([d.km for d in topo_distance])\n",
    "acc_1km = len([d for d in topo_distance if d.km<=1])/len(topo_distance)\n",
    "acc_10km = len([d for d in topo_distance if d.km<=10])/len(topo_distance)\n",
    "acc_50km = len([d for d in topo_distance if d.km<=50])/len(topo_distance)\n",
    "acc_80km = len([d for d in topo_distance if d.km<=80])/len(topo_distance)\n",
    "acc_161km = len([d for d in topo_distance if d.km<=161])/len(topo_distance)\n",
    "\n",
    "print(f'Macro precision: {macro_precision:.3f}')\n",
    "print(f'Macro recall: {macro_recall:.3f}')\n",
    "print(f'Macro F1: {macro_f1:.3f}')\n",
    "print('#####################')\n",
    "print(f'Mean distance : {mean_d:.1f}')\n",
    "print(f'Median distance : {median_d:.3f}')\n",
    "print(f'Acc@1km : {acc_1km:.3f}')\n",
    "print(f'Acc@10km : {acc_10km:.3f}')\n",
    "print(f'Acc@50km : {acc_50km:.3f}')\n",
    "print(f'Acc@80km : {acc_80km:.3f}')\n",
    "print(f'Acc@161km : {acc_161km:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo_llama.gazetteer import Gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'place_id': 278439064,\n",
       "  'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright',\n",
       "  'osm_type': 'relation',\n",
       "  'osm_id': 5758583,\n",
       "  'lat': '37.3247408',\n",
       "  'lon': '-113.0048035752838',\n",
       "  'class': 'boundary',\n",
       "  'type': 'national_park',\n",
       "  'place_rank': 25,\n",
       "  'importance': 0.4973522186722954,\n",
       "  'addresstype': 'national_park',\n",
       "  'name': 'Zion National Park',\n",
       "  'display_name': 'Zion National Park, Washington County, Utah, United States',\n",
       "  'boundingbox': ['37.1413497', '37.5042917', '-113.2282863', '-112.8631483']}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nominatim = Gazetteer(polygon=False)\n",
    "\n",
    "nominatim.query('Zion National Park', user_agent='UA_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-lm-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
